{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np                                   # Math and calculations\nimport pandas as pd                                  # Data manipulation\nfrom keras.models import Sequential                  # Sequential model library from keras\nfrom keras.layers import Dense, Activation           # Dense keras layers of nodes, activation functions\nfrom keras.optimizers import Adam                    # Adam optimizer\nfrom keras.metrics import CategoricalCrossentropy    # Calculate loss\nfrom keras.losses import mean_squared_error          # used for testing\nfrom sklearn.model_selection import train_test_split # split data","execution_count":102,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Firstly, all major packages are imported. Although the keras modules are all contained within the tensorflow library, I imported methods and classes in order to improve code readability (i.e. not having to write tf.keras.metrics.BinaryCrossentropy in code)."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"widgets_train = pd.read_csv(\"../input/pl234142-widgets/pl234142.csv\", thousands=',')\nprint(widgets_train.head())\nthing = widgets_train.copy()","execution_count":103,"outputs":[{"output_type":"stream","text":"   User ID             name  Gender  Age  EstimatedSalary  Purchased\n0    10000      Bruce Evans  Female   23            67928          0\n1    10001    Maria Stevens    Male   47           147285          1\n2    10002      Brett Banks    Male   31           123436          1\n3    10003  Danielle Snyder  Female   28           130425          0\n4    10004    Jessica Smith  Female   48            90212          1\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"The data is imported and copied into thing, which is then printed for basic analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"Sex_Binary = []\nfor x in thing[\"Gender\"]:\n    if x.lower() == \"male\":\n        Sex_Binary.append(1)\n    elif x.lower() == \"female\":\n        Sex_Binary.append(0)\n    else:\n        Sex_Binary.append(\"MISSING VALUE\")\n        print(\"missing value\")\nthing[\"GenderBin\"] = Sex_Binary\nprint(thing.head())","execution_count":104,"outputs":[{"output_type":"stream","text":"   User ID             name  Gender  Age  EstimatedSalary  Purchased  \\\n0    10000      Bruce Evans  Female   23            67928          0   \n1    10001    Maria Stevens    Male   47           147285          1   \n2    10002      Brett Banks    Male   31           123436          1   \n3    10003  Danielle Snyder  Female   28           130425          0   \n4    10004    Jessica Smith  Female   48            90212          1   \n\n   GenderBin  \n0          0  \n1          1  \n2          1  \n3          0  \n4          0  \n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Using code I had previously written, I loop through the \"Gender\" label in my data, and manually append a 1 to represent male, and a 0 to represent female. Although I do have an else statement to handle missing data, no data was missing. Finally, this new binary gender label is added to the pandas dataframe, which is then printed."},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = thing.corr()\nprint(corr_matrix[\"Purchased\"].sort_values())","execution_count":105,"outputs":[{"output_type":"stream","text":"EstimatedSalary   -0.040757\nGenderBin          0.015427\nAge                0.041791\nUser ID            0.044952\nPurchased          1.000000\nName: Purchased, dtype: float64\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"The correlation matrix is printed for the \"Purchased\" label. As you can see, the correlation for all 4 usable attributes is very poor. This could've been a coincidence that occurred in the process of generating the data, or perhaps this bad data was created with malicious intent. *raises eyebrow*"},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(type(thing[\"EstimatedSalary\"]).values)\nthing2=thing.copy()\nthing2.pop('Purchased')\nthing2.pop('Gender')\nthing2.pop('name')\nX2 = np.array(thing2)\nX = X2.reshape(1000,4)\nprint(X)\n#print(thing2)\ny = thing['Purchased']\n#print(y)\n\n#split training and test data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","execution_count":106,"outputs":[{"output_type":"stream","text":"[[ 10000     23  67928      0]\n [ 10001     47 147285      1]\n [ 10002     31 123436      1]\n ...\n [ 10997     30 112727      0]\n [ 10998     24  41431      1]\n [ 10999     34 140120      0]]\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Another copy of the data is created in order to remove columns while not losing anything permanently. The \"Purchased\", \"Gender\", and \"name\" columns of the dataframe are removed using the pop() method. This new dataframe is made into a numpy array, which is then converted into a format of 1000 lists, each with a length of 4 using the reshape() method from numpy. This is the X training data for the ML algorithm. The \"Purchased\" column from the original dataframe is then turned saved as the training value for y."},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.random.set_seed(7)\n\n#creating the keras model\nmodel = Sequential()\n\n#first layer uses ReLU activation. Input is the proper shape for model\nmodel.add(Dense(4, input_shape=(1000,4), activation='relu'))\n\n#hidden layer using ReLU activation.\nmodel.add(Dense(25, activation='relu'))\n\n#final layer outputs one node using tanh activation\nmodel.add(Dense(1, activation='tanh'))\n\nprint(\"Layers added.\")","execution_count":120,"outputs":[{"output_type":"stream","text":"Layers added.\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"A sequential keras model is created, with an input layer, 1 hidden layer (I couldn't find any benefits for more than one in this use case), and an output layer. The first two layers use the Rectified Linear Unit (ReLU) activation function due to its simplicity, accuracy, efficiency, and widespread support (i.e. number of related Stack Overflow threads). Since the final prediction value is supposed to be a -1, 0, or a 1, the output layer uses the tanh activation function, as it is nonlinear, and capable of categorizing these three data values."},{"metadata":{"trusted":true},"cell_type":"code","source":"#compile the model; since output is non-binary, categorical crossentropy is used to calculate loss.\n#Adam optimizer is used for decent speed and accuracy (although I'm not entirely sure how it works.)\n#Accuracy argument used to determine metrics.\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])\n\n# Fit the model\nmodel.fit(X_train, y_train, epochs=10)\nprint(\"Compiled and Fitted.\")\n\nmodel.evaluate(X_test, y_test)","execution_count":121,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n25/25 [==============================] - 0s 1ms/step - loss: 5.1260e-08 - accuracy: 0.4875\nEpoch 2/10\n25/25 [==============================] - 0s 1ms/step - loss: 5.1260e-08 - accuracy: 0.4875\nEpoch 3/10\n25/25 [==============================] - 0s 1ms/step - loss: 5.1260e-08 - accuracy: 0.4875\nEpoch 4/10\n25/25 [==============================] - 0s 1ms/step - loss: 5.1260e-08 - accuracy: 0.4875\nEpoch 5/10\n25/25 [==============================] - 0s 1ms/step - loss: 5.1260e-08 - accuracy: 0.4875\nEpoch 6/10\n25/25 [==============================] - 0s 1ms/step - loss: 5.1260e-08 - accuracy: 0.4875\nEpoch 7/10\n25/25 [==============================] - 0s 1ms/step - loss: 5.1260e-08 - accuracy: 0.4875\nEpoch 8/10\n25/25 [==============================] - 0s 1ms/step - loss: 5.1260e-08 - accuracy: 0.4875\nEpoch 9/10\n25/25 [==============================] - 0s 1ms/step - loss: 5.1260e-08 - accuracy: 0.4875\nEpoch 10/10\n25/25 [==============================] - 0s 1ms/step - loss: 5.1260e-08 - accuracy: 0.4875\nCompiled and Fitted.\n7/7 [==============================] - 0s 1ms/step - loss: 4.5300e-08 - accuracy: 0.5350\n","name":"stdout"},{"output_type":"execute_result","execution_count":121,"data":{"text/plain":"[4.5299529460862686e-08, 0.5350000262260437]"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"The compile() and fit() methods are called on the method, using categorical crossentropy to calculate loss, and the Adam optimizer. The accuracy metric is used to determine how accurate the model is. Interestingly, the loss and accuracy remain static at   5.0068e-08 and 0.5040, respectively. What could I have done to make this model more accurate?"}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}